# -*- coding: utf-8 -*-
"""01_register_data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15varczMUrG9sE4wz2vnBfavbNThdGCrR
"""

import os, json
import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, classification_report
from sklearn.ensemble import RandomForestClassifier
import joblib

from huggingface_hub import HfApi, hf_hub_download

HF_DATASET_REPO = os.environ["HF_DATASET_REPO"]
HF_MODEL_REPO   = os.environ["HF_MODEL_REPO"]
SEED = int(os.environ.get("SEED", "42"))

REPORT_DIR = "reports"
MODEL_DIR = "models"
os.makedirs(REPORT_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)

def load_split(filename: str) -> pd.DataFrame:
    path = hf_hub_download(
        repo_id=HF_DATASET_REPO,
        repo_type="dataset",
        filename=f"data/processed/{filename}",
    )
    return pd.read_csv(path)

def build_pipeline(X: pd.DataFrame):
    cat_cols = X.select_dtypes(include=["object"]).columns.tolist()
    num_cols = [c for c in X.columns if c not in cat_cols]

    numeric = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="median"))
    ])
    categorical = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore"))
    ])

    pre = ColumnTransformer(
        transformers=[
            ("num", numeric, num_cols),
            ("cat", categorical, cat_cols),
        ]
    )

    clf = RandomForestClassifier(
        random_state=SEED,
        n_jobs=-1,
        class_weight="balanced"
    )

    pipe = Pipeline(steps=[
        ("preprocess", pre),
        ("model", clf)
    ])
    return pipe

def main():
    train_df = load_split("train.csv")
    test_df  = load_split("test.csv")

    y_train = train_df["ProdTaken"].astype(int)
    X_train = train_df.drop(columns=["ProdTaken"])
    y_test  = test_df["ProdTaken"].astype(int)
    X_test  = test_df.drop(columns=["ProdTaken"])

    pipe = build_pipeline(X_train)

    param_grid = {
        "model__n_estimators": [200, 400],
        "model__max_depth": [None, 8, 16],
        "model__min_samples_split": [2, 10],
        "model__min_samples_leaf": [1, 5],
        "model__max_features": ["sqrt", "log2"],
    }

    gs = GridSearchCV(
        estimator=pipe,
        param_grid=param_grid,
        scoring="roc_auc",
        cv=5,
        n_jobs=-1,
        verbose=1
    )

    gs.fit(X_train, y_train)
    best = gs.best_estimator_

    # Evaluate
    proba = best.predict_proba(X_test)[:, 1]
    pred  = (proba >= 0.5).astype(int)

    metrics = {
        "roc_auc": float(roc_auc_score(y_test, proba)),
        "f1": float(f1_score(y_test, pred)),
        "accuracy": float(accuracy_score(y_test, pred)),
        "best_params": gs.best_params_,
    }

    # Save artifacts locally
    model_path = f"{MODEL_DIR}/best_model.joblib"
    joblib.dump(best, model_path)

    with open(f"{REPORT_DIR}/metrics.json", "w") as f:
        json.dump(metrics, f, indent=2)

    with open(f"{REPORT_DIR}/classification_report.txt", "w") as f:
        f.write(classification_report(y_test, pred))

    print("✅ Metrics:", metrics)

    # Register model on Hugging Face Model Hub
    api = HfApi()
    api.create_repo(repo_id=HF_MODEL_REPO, repo_type="model", exist_ok=True)

    api.upload_file(
    path_or_fileobj=model_path,
    path_in_repo="best_model.joblib",
    repo_id=HF_MODEL_REPO,
    repo_type="model",
)
    api.upload_file(
    path_or_fileobj=f"{REPORT_DIR}/metrics.json",
    path_in_repo="metrics.json",
    repo_id=HF_MODEL_REPO,
    repo_type="model",
)
    api.upload_file(
    path_or_fileobj=f"{REPORT_DIR}/classification_report.txt",
    path_in_repo="classification_report.txt",
    repo_id=HF_MODEL_REPO,
    repo_type="model",
)


    print("✅ Uploaded model + metrics to HF model repo:", HF_MODEL_REPO)

if __name__ == "__main__":
    main()